# 索引

## 索引的类型

1. B+tree索引

   1. innodb只支持B+tree索引，。B+tree适合搜索范围和前缀搜索
   2. B+tree索引的叶子节点存储数据，所以查询的性能是一致的。而且查找索引最少是两次，第一次查询非聚簇索引拿到主键值，再查询局促索引得到其它列的值
   3. 对于聚簇索引，叶子节点包含行所有的值；对于非聚簇索引，叶子节点只有主键

2. memory引擎和NDB集群引擎支持hash索引

   1. hash索引适合=, <=>和in
   2. hash索引不支持范围查询，比如小于，大于，between等
   3. hash索引只能对建立索引的列AB，当查询语句里都包含AB才可以
   4. hash索引一般来说非常快，除非有很多的hash碰撞，导致链表中有大量数据，那么此时必须一个一个地遍历链表找到数据

3. 前缀索引：首先要计算出来有多长的前缀可以保证数据是完整的，别只取第一位，那没什么意义啊

   ﻿ALTERTABLEsakila.city_demoADDKEY(city(7));

4. 覆盖索引：二级索引中不光存储主键，也存储列的值。这样就不需要再次查询聚簇索引了

 ## 不能利用索引的情况

1. null值不能加入索引
2. 不适合值很少的列，比如性别
3. 如果条件中有or，那么只能对or里的所有列加索引
4. mysql不支持对有计算的where查询有索引，但是postgresql就支持
5. Not，not in，like'%a%', <>

## 最左前缀原则

1. 比如类型等集中数据放在索引的前面，数据越分散就越放在后面
2. 如果对列A和B加索引，那么where A='' and B='' 会使用该索引，而且where A=''也会使用索引，但是where
   B=''则不会使用索引。
3. 如果对列ABC加索引，那么where A='' and C='', 不会使用索引. 
4. 如果对列AB加索引，那么where A='' and B like 'value%'，会使用索引; 
5. 如果对列AB加索引，那么where A='' and B like '%value%'， 或者where A='' and B like '%value'，不会使用索引
6. 对于order by语句，也要遵循最左前缀原则。order列的顺序和索引的顺序一样，或者只用索引从左开始的一部分；如果order by有的列正序，有的列倒序，那么也用不上索引;
7. Group by 和order by是一样的

## 什么情况下需要加索引

1. 小型数据表全表查询最快，中型号数据表建立索引，大型数据表建立分区。数据库可建立分区表来按照某种逻辑对数据进行物理分区
2. 经常查询的列需要加索引；
3. 经常用作表连接的列需要加索引；
4. 经常需要排序和范围查询的列需要加索引；

## 索引的best practice
1. 在遵循这些规则的基础上，最好explain看看真正的执行计划

2. 索引最好是能在当前索引上增加列，而不是新建

3. 索引可以进行碎片整理

4. 去掉冗余的索引，建立联合索引

5. 最左前缀原则，要注意group by,order by, 以及where的顺序

6. 选择性越高的列，就放在索引的最前面。但是选择性高于20%，比如性别的选择性就是50%，就没有必要加索引了. 如果计算选择性？Select count(distinct(列)) /count(列)

7. 要尽量避免在查询中使用多个索引，然后merge结果（见索引合并

## 索引下推
默认是开启的。看起来还是开启比较好
就是where name like 'a%' and age<10 语句中，先利用索引查出name以a开头的，然后去掉age小于10的，叫做索引下推。
关闭索引下推，那么先用索引查出name以a开头的，然后回表查询过滤age小于10的，再返回结果。

## 索引合并
当有多个and时，可能会用到多个索引，这时就会在explain中看到merge的操作
最好能避免merge操作
也可以用ignore index来忽略某些索引



## SQL优化
1. 查看查询计划，找到慢查询
2. 在用实际的数据量级进行测试，找出慢查询和不适合的索引
3. 从业务上优化sql
4. 组合多个子查询，来代替一个复杂的查询
5. 不要对数值少比如性别这一类创建索引；不要对大数据创建；写操作多也不要；注意某些数据库版本的加索引的锁表问题。
6. 建立合适的索引
7. 从业务上分解复杂的查询，将复杂的sql分解为多个简单的查询
8. 是否请求了不需要的数据
	A. 检查是否请求了多余的行
	B. 检查是否返回了多余的列
	C. 重复查询相同的数据，可以用缓存
9. 是否扫描了额外的记录
	A. 使用慢日志来查找慢sql。在需要的时候才开启：注意看响应时间，扫描的行数和返回的行数




## 事务的特性
Atomic：一个事务是原子性的
Consistency：在某一个时刻，数据都是一致的
Isolation：一个事务对于另外一个事务，在提交之前都是不可见的。这里有事务隔离级别，see below
Dubability：持久性的。事务操作的数据可以持久化被保存起来

## 事务有什么问题？

## mvcc版本并发控制
在repeated read和commited read隔离级别下，使用MVCC版本并发控制：
优点是：大多数的读操作不需要加锁，就可以实现repeated read；
缺点是：需要额外的空间保存多版本的行；写操作依旧需要加行级锁；读取的是快照，所以要读最新的还是需要加锁
在数据表上加两个隐藏列，当前版本号和删除版本号。事务开始时，取当前的版本号作为事务的版本号
1. select操作：只查询低于或者等于事务版本号的未删除的行，读取的是快照
2. insert操作：新增一行并且设置版本号
3. delete操作：将删除版本号设置值
4. update操作：新增一行并且设置新的版本号，将旧行的删除版本号设置值

## Select  -- 快照读和当前读
1. 快照读就是默认的select语句，读取时无需加锁。在repeated read和commited read隔离级别下，读到的都是低于或者等于当前版本号的行。
2. 当前读，就需要加锁。在repeated read下加间隙锁，保证事务中间新行不被读入
	• Select * FROM TABLE LOCK in share MODE
	• SELECT * FROM TABLE FOR UPDATE
	• INSERT
	• UPDATE
	• DELETE 

## 幻读 -- mvcc版本并发控制 vs 间隙锁
默认的select操作读取的是快照，mvcc解决了幻读的问题；
当需要当前读时，用的就是间隙锁。

## 隔离级别
可以只改变当前回话的隔离级别, 设定session时只改变当前会话的隔离级别
SET SESSION TRANSACTION ISOLATION LEVEL READ UNCOMMITTED
1. Read uncommited 未提交读
	i. 事务们随便玩
	ii. 脏读：在A事务未提交的情况下，B事务读到了A的改变。
2. Read commited 提交读
	i. 在事务A read时，其它所有写入事务已经完毕；事务A不会影响到其他所有事务
	ii. 在A事务未提交的情况下，B事务读不到A的改变
	iii. A事务未提交，B读到1000；A事务提交后，B读到2000. 所以B在一个事务内读到两次不同
3. Repeatable Read 可重复读
	i. 在事务A 第一次read时，其它所有edit事务已经完毕；新增的update/delete事务必须等待事务A结束；insert事务不会等待
	ii. A事务读到1000，B事务尝试修改1000-->500, 不会成功；但是如果B事务增加500，成功，这就是幻读
	iii. 注意最新的mysql支持间隙锁，可以避免幻读的问题。对加了非唯一的索引的列加间隙锁，不光锁定当前行，并且对索引中的间隙进行锁定，避免读到新添加的行
4. Serializable 可串行化
	i. 简而言之，所有事务统统排队
5. 各大数据库的默认隔离级别
	i. mysql使用Repeatable Read
	ii. Postgres：READ COMMITTED
	iii. MS Sql: READ COMMITTED
	iv. Oracle: READ COMMITTED

## MySql数据的量级
单台机器的数据量在3~5TB，甚至10TB以下都运行的不错，前提是很好的利用了硬件资源，并且优化了
如果增大到10TB以上，就要考虑使用数据仓库了

## 数据库和数据仓库

|         | 数据库                                                     | 数据仓库                                        |
| ------- | ---------------------------------------------------------- | ----------------------------------------------- |
| 操作     | 操作型处理   OLTP操作的，是online transactional processing | 分析性处理   OLAP，online analytical processing |
| 工具选型 | Mysql,mssql,oracle,postgres… | Oracle   exadata, Vertica, Teradata…. |
| 规则 | 遵循范式 | 为了更好的查询，会有大量冗余 |
| 数据 | 一般只记录最新的数据；   数据可以修改 | 记录历史数据；   数据是只读的，只能追加，不能修改 |
| 性能 | 性能要求高，相应时间短 | 性能要求宽松 |
| 数据量级 | MySQL单机最好3T~5T，最多10T | 大于10T |

## MySQL的存储引擎

### 存储引擎的粒度

存储引擎可以按表，事务回滚无法回滚不支持事务的表

### InnoDB的长处
• 设计为执行大量的short lived的事务，而且很少会被回滚
• 性能良好
• 崩溃自动恢复
• 存储格式是平台独立的，可以移植
• 从磁盘读取数据时，可预测性预读来提高查询性能
• 自适应哈希索引
• 加速插入操作的插入缓冲区
• 可以使用innodb+Sphinx来支持全文检索

### InnoDB的特点
• 聚簇索引对查询有很好的性能
• 二级索引必须包含主键列，所以如果表很大，那么主键列应该尽可能地小

### MyISAM
不建议使用。就算是MyISAM比InnoDB要快，但是随着数据量级的上升，各种崩溃，丢数据也随之而来。相反innodb就很稳定，而且聚簇索引也非常快甚至快过MyISAM。
• 支持地理空间类型存储和搜索
• 支持全文检索
• 因为没有事务，所以插入速度很快，适合日志型的应用（但是日志不都放在ES里了么）
• 不支持事务和行级锁，只有表级锁。读取时对整张表加共享锁，写入时对整张表加排它锁。所以当查询变得非常慢时，很大概率就是因为表级锁导致的
• 修复。不像innodb一样，自动修复。而是必须手动修复，而且非常慢

### CSV
可以把CSV文件当做数据文件来使用

### Memory
• 表的数据存储来内存里，不持久化。
• 数据库重启后表的数据会丢失，但是表结构还在
• 优点是查询速度很快
• 表级锁，所以性能一般
• 适合保存计算中的聚合数据，与临时表不同，临时表只能被当前连接可见，但是memory表可以对所有连接可见。

### NDB集群引擎

## Lock in share mode VS for update
1. Lock in share mode加了共享锁，其它的transaction可以快照读，也可以share读
2. For update是加了排它锁。其它transaction可以快照读，但是不能share读

## 查询结果缓存
SHOW VARIABLES LIKE '%query_cache%';
query_cache_type：0不用缓存；1用缓存；2是按需使用缓存
如果值为1，那么不要使用缓存，那么：SELECT SQL_NO_CACHE * FROM my_table WHERE condition;
如果值为2，而且要使用缓存，那么：SELECT SQL_CACHE * FROM my_table WHERE condition;

## 对Explain参数及重要参数的理解？
type：访问类型，查看SQL到底是以何种类型访问数据的。
key：使用的索引，MySQL用了哪个索引，有时候MySQL用的索引不是最好的，需要force index()。
rows：最大扫描的列数。
extra：重要的额外信息，特别注意损耗性能的两个情况，using filesort和using temporary。

## 索引与锁有什么关系？
记录锁时基于唯一索引（包括主键索引）实现的，所以如果表没有索引，那么就会变成表级锁。
间隙锁时基于非唯一索引实现的，快照读不会加锁，但是当前读就会用到间隙锁。
在某些版本里，新增索引会导致锁表；如果数据量大的话，会导致CRUD缓慢；所以要在夜深人静时加索引，最好评估下加索引的时间

## B+tree 如何进行优化？
1. 最左前缀原则
2. 联合索引
3. 覆盖索引

## MySQL表设计及规范？
满足三个范式：
列是原子的，不可分割；
行是唯一的，不能有冗余，有冗余则拆；
行中的数据都从属于主键，都是直接关系
反范式来取得性能优化

## 死锁？
有两个事务，事务1先修改表A的行1然后表B的行2，事务2先修改表B的行2然后表A的行1。
mysql的innodb引擎会发现死锁，并将其中锁定行数最少的事务，报错并进行回滚操作。
死锁的行为和数据库引擎相关的。以同样的顺序执行语句，有的引擎会发生死锁，有的则不会。
死锁有时候与语句的执行顺序导致，有时候跟引擎的实现方式导致的。

## 死锁的监控？

## 自增长与锁 ，锁的算法，锁问题，锁升级是什么？
行锁升级为表锁
1. 类型转换
2. 没有主键导致没有行级锁

